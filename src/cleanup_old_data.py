# src/cleanup_old_data.py
import os
import re
import logging
from pathlib import Path

LOG_FMT = "%(asctime)s | %(levelname)s | %(message)s"
logging.basicConfig(level=logging.INFO, format=LOG_FMT)

DATA_DIR = Path("data/processed")
TIMESTAMP_PATTERN = re.compile(r"_\d{8}_\d{6}")

def cleanup_processed_folder():
    """
    Remove arquivos antigos (com timestamp no nome) dentro de data/processed,
    preservando CSVs fixos e o ads_store.json.
    """
    if not DATA_DIR.exists():
        logging.warning("‚ö†Ô∏è Pasta data/processed n√£o existe.")
        return

    removed = 0
    skipped = 0

    for path in DATA_DIR.glob("*"):
        if path.is_dir():
            continue

        name = path.name

        # mant√©m os CSVs fixos e arquivos essenciais
        if name.endswith(".csv") and not TIMESTAMP_PATTERN.search(name):
            skipped += 1
            continue
        if name == "ads_store.json":
            skipped += 1
            continue

        # remove arquivos com timestamp no nome
        if TIMESTAMP_PATTERN.search(name):
            try:
                path.unlink()
                logging.info(f"üóëÔ∏è Removido: {name}")
                removed += 1
            except Exception as e:
                logging.error(f"‚ùå Erro ao remover {name}: {e}")
        else:
            skipped += 1

    logging.info(f"‚úÖ Limpeza conclu√≠da ‚Äî {removed} removidos, {skipped} preservados.")

if __name__ == "__main__":
    cleanup_processed_folder()
